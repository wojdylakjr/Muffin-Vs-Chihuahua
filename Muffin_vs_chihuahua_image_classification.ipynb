{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuxLLaRHYOV4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import time\n",
        "!pip install kaggle\n",
        "!pip3 install ann_visualizer\n",
        "!pip install graphviz\n",
        "from ann_visualizer.visualize import ann_viz\n",
        "from graphviz import Source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTjXovRdb7MO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO1GBLd1ehXN"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M04R-UIMehjc"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjUCF-GMcASz"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d samuelcortinhas/muffin-vs-chihuahua-image-classification\n",
        "!unzip muffin-vs-chihuahua-image-classification.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hFc_Vhl5RHn"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    x = []\n",
        "    y = []\n",
        "    classes = ['chihuahua', 'muffin']\n",
        "    dataset_path = '/content/dataset'\n",
        "\n",
        "    # Load training images and labels\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, 'train', class_name)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (32, 32))\n",
        "            x.append(img)\n",
        "            y.append(classes.index(class_name))\n",
        "\n",
        "    # Load testing images and labels\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, 'test', class_name)\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, (32, 32))\n",
        "            x.append(img)\n",
        "            y.append(classes.index(class_name))\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf1SOFrG5Xf8"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "x,y = load_dataset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D80AquX-LDw"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history, learning_rate, batch_size, epochs, model):\n",
        "    # Plot the training loss and accuracy on the same plot\n",
        "    epochs = range(1, len(history.history['loss']) + 1)\n",
        "    plt.plot(epochs, history.history['loss'], 'b',label='Training Loss')\n",
        "    plt.plot(epochs, history.history['accuracy'], 'r', label='Training Accuracy')\n",
        "    plt.plot(epochs, [1 - accuracy for accuracy in history.history['val_accuracy']], label='Validation zero - one loss', marker='o', linestyle='-', color='black')\n",
        "\n",
        "    plt.title('Training and Validation Loss and Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.suptitle(f\"Number of epochs: { epochs}  Learning rate:  {learning_rate}  Batch size  {batch_size} {model}\", ha='center')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcqd1qbUM6_4"
      },
      "outputs": [],
      "source": [
        "def create_model1():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    ann_viz(model, view=True, title=\"Neural network plot\")\n",
        "    Source.from_file('/content/network.gv')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djWDNM3bQ7qY"
      },
      "outputs": [],
      "source": [
        "def create_model2():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    ann_viz(model, view=True, title=\"Neural network plot\")\n",
        "    Source.from_file('/content/network.gv')\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpI7PuB5SN5p"
      },
      "outputs": [],
      "source": [
        "def create_model3():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    ann_viz(model, view=True, title=\"Neural network plot\")\n",
        "    Source.from_file('/content/network.gv')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RYwqOxJfBS6"
      },
      "outputs": [],
      "source": [
        "n_splits = 5\n",
        "\n",
        "hyperparameters = {\n",
        "    'learning_rate': [0.0001],\n",
        "    'batch_size': [128],\n",
        "    'epochs': [8,16,24],\n",
        "}\n",
        "\n",
        "results = []\n",
        "# Define the K-Fold cross-validation\n",
        "kfold = KFold(n_splits=5)\n",
        "fold = 1\n",
        "cv_accuracy = []\n",
        "cv_loss = []\n",
        "cv_zero_one_loss = []\n",
        "learning_times = []\n",
        "\n",
        "for hyperparam in product(*hyperparameters.values()):\n",
        "    hyperparam = dict(zip(hyperparameters.keys(), hyperparam))\n",
        "    learning_rate = hyperparam['learning_rate']\n",
        "    batch_size = hyperparam['batch_size']\n",
        "    epochs = hyperparam['epochs']\n",
        "    fold = 1\n",
        "    for train_index, validation_index in kfold.split(x, y):\n",
        "        # Split the data into training and validation sets\n",
        "        x_train_fold, x_validation_fold = x[train_index], x[validation_index]\n",
        "        y_train_fold, y_validation_fold = y[train_index], y[validation_index]\n",
        "\n",
        "        print(f\"Fold: {fold}\")\n",
        "        print(\"x_train_fold size: \", len(x_train_fold))\n",
        "        print(\"x_validation_fold size: \", len(x_validation_fold))\n",
        "        print(\"y_train_fold size: \", len(y_train_fold))\n",
        "        print(\"y_validation_fold size: \", len(y_validation_fold))\n",
        "\n",
        "        # Create the model\n",
        "        model = create_model2()\n",
        "        model.summary()\n",
        "\n",
        "        # Compile the model\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "        model.compile(optimizer=optimizer, loss=binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "        # Train the model\n",
        "        start = time.time()\n",
        "        history = model.fit(x_train_fold, y_train_fold, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_validation_fold, y_validation_fold))\n",
        "        end = time.time()\n",
        "        learning_times.append(end - start) # time in seconds\n",
        "\n",
        "        plot_training_history(history, learning_rate, batch_size, epochs, \"model2\")\n",
        "\n",
        "        validation_loss, validation_accuracy = model.evaluate(x_validation_fold, y_validation_fold, verbose=0)\n",
        "        validation_zero_one_loss = 1 - validation_accuracy\n",
        "\n",
        "        cv_accuracy.append(validation_accuracy)\n",
        "        cv_loss.append(validation_loss)\n",
        "        cv_zero_one_loss.append(validation_zero_one_loss)\n",
        "\n",
        "        print(\"test accuracy:\", validation_accuracy)\n",
        "        print(\"test loss:\", validation_loss)\n",
        "        print(\"Zero-One Loss on Test Fold: \",validation_zero_one_loss )\n",
        "\n",
        "        #get_metrics_result\n",
        "        print(\"get_metrics_result: \", model.get_metrics_result())\n",
        "        # Store the results\n",
        "        results.append({\n",
        "                  'hyperparameters': hyperparam,\n",
        "                  'val_loss': validation_loss,\n",
        "                  'val_acc': validation_accuracy,\n",
        "              })\n",
        "        fold += 1\n",
        "\n",
        "    # Compute the average cross-validated accuracy\n",
        "    mean_cv_accuracy = np.mean(cv_accuracy)\n",
        "    mean_cv_loss = np.mean(cv_loss)\n",
        "    mean_cv_zero_one_loss = np.mean(cv_zero_one_loss)\n",
        "    mean_learning_time = np.mean(learning_times)\n",
        "    print(\"Cross-Validated Accuracy:\", mean_cv_accuracy)\n",
        "    print(\"Cross-Validated Loss:\", mean_cv_loss)\n",
        "    print(\"mean_cv_zero_one_loss\", mean_cv_zero_one_loss)\n",
        "    print(\"cv_zero_one_loss\", cv_zero_one_loss)\n",
        "    print(\"mean_learning_time\",mean_learning_time )\n",
        "    print(\"learning times\",learning_times )\n",
        "    cv_accuracy.clear()\n",
        "    cv_loss.clear()\n",
        "    cv_zero_one_loss.clear()\n",
        "    learning_times.clear()\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}